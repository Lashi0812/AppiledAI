{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import gzip\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on ufunc:\n",
      "\n",
      "expit = <ufunc 'expit'>\n",
      "    expit(x, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj])\n",
      "    \n",
      "    expit(x, out=None)\n",
      "    \n",
      "    Expit (a.k.a. logistic sigmoid) ufunc for ndarrays.\n",
      "    \n",
      "    The expit function, also known as the logistic sigmoid function, is\n",
      "    defined as ``expit(x) = 1/(1+exp(-x))``.  It is the inverse of the\n",
      "    logit function.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x : ndarray\n",
      "        The ndarray to apply expit to element-wise.\n",
      "    out : ndarray, optional\n",
      "        Optional output array for the function values\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    scalar or ndarray\n",
      "        An ndarray of the same shape as x. Its entries\n",
      "        are `expit` of the corresponding entry of x.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    logit\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    As a ufunc expit takes a number of optional\n",
      "    keyword arguments. For more information\n",
      "    see `ufuncs <https://docs.scipy.org/doc/numpy/reference/ufuncs.html>`_\n",
      "    \n",
      "    .. versionadded:: 0.10.0\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from scipy.special import expit, logit\n",
      "    \n",
      "    >>> expit([-np.inf, -1.5, 0, 1.5, np.inf])\n",
      "    array([ 0.        ,  0.18242552,  0.5       ,  0.81757448,  1.        ])\n",
      "    \n",
      "    `logit` is the inverse of `expit`:\n",
      "    \n",
      "    >>> logit(expit([-2.5, 0, 3.1, 5.0]))\n",
      "    array([-2.5,  0. ,  3.1,  5. ])\n",
      "    \n",
      "    Plot expit(x) for x in [-6, 6]:\n",
      "    \n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> x = np.linspace(-6, 6, 121)\n",
      "    >>> y = expit(x)\n",
      "    >>> plt.plot(x, y)\n",
      "    >>> plt.grid()\n",
      "    >>> plt.xlim(-6, 6)\n",
      "    >>> plt.xlabel('x')\n",
      "    >>> plt.title('expit(x)')\n",
      "    >>> plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(expit)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def sigmoid_prime(z):\n",
    "    return expit(z)*(1-expit(z))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x2507fe05090>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "z = np.linspace(-10,10,100)\n",
    "plt.plot(z,expit(z),label=\"Sigmoid\")\n",
    "plt.plot(z,sigmoid_prime(z),label=\"Derivative\")\n",
    "plt.legend()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self,sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.bias = [np.random.rand(y,1) for y in sizes[1:]]\n",
    "        self.weights =[np.random.randn(y,x) for x,y in zip(sizes[:-1],sizes[1:])]\n",
    "\n",
    "    def feedforward(self,a):\n",
    "        for b,w in zip(self.bias,self.weights):\n",
    "            a = expit(np.dot(w,a)+b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self,training_data,epochs,mini_batch_size,eta,test_data=None):\n",
    "        if test_data:n_test = len(test_data)\n",
    "        n = len(training_data)\n",
    "        for j in range(epochs):\n",
    "            np.random.shuffle(training_data)\n",
    "            mini_batches = [training_data[k:k+mini_batch_size]\n",
    "                            for k in range(0,n,mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch,eta)\n",
    "            if test_data:\n",
    "                print(f\"Epoch {j} : {self.evaluate(test_data)} / {n_test}\")\n",
    "            else:\n",
    "                print(f\"Epoch {j} completed.\")\n",
    "\n",
    "    def update_mini_batch(self,mini_batch,eta):\n",
    "        new_b = [np.zeros_like(b) for b in self.bias]\n",
    "        new_w = [np.zeros_like(w) for w in self.weights]\n",
    "\n",
    "        for x,y in mini_batch:\n",
    "            delta_new_b,delta_new_w = self.backprop(x,y)\n",
    "            new_b = [nb+dnb for nb,dnb in zip(new_b,delta_new_b)]\n",
    "            new_w = [nw+dnw for nw,dnw in zip(new_w,delta_new_w)]\n",
    "\n",
    "        self.weights = [w -(eta/len(mini_batch))*nw\n",
    "                        for w,nw in zip(self.weights,new_w)]\n",
    "        self.bias = [b- (eta/len(mini_batch))*nb\n",
    "                     for b, nb in zip(self.bias,new_b)]\n",
    "\n",
    "    def backprop(self,x,y):\n",
    "        new_w = [np.zeros_like(w) for w in self.weights]\n",
    "        new_b = [np.zeros_like(b) for b in self.bias]\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x]\n",
    "        z_weighted_inputs = []\n",
    "        for b,w in zip(self.bias,self.weights):\n",
    "            z_weighted_input = np.dot(w,activation) + b\n",
    "            z_weighted_inputs.append(z_weighted_input)\n",
    "            activation = expit(z_weighted_input)\n",
    "            activations.append(activation)\n",
    "\n",
    "        # output error\n",
    "        delta =self.cost_derivative(activations[-1],y) * sigmoid_prime(z_weighted_inputs[-1])\n",
    "        new_b[-1] = delta\n",
    "        new_w[-1] = np.dot(delta , activations[-2].T)\n",
    "\n",
    "        for l in range(2,self.num_layers):\n",
    "            z_weighted_input = z_weighted_inputs[-l]\n",
    "            sp = sigmoid_prime(z_weighted_input)\n",
    "            delta = np.dot(self.weights[-l+1].T,delta) * sp\n",
    "            new_b[-l] = delta\n",
    "            new_w[-l] = np.dot(delta, activations[-l-1].T)\n",
    "\n",
    "        return new_b,new_w\n",
    "\n",
    "    def evaluate(self,test_data):\n",
    "        test_results = [(np.argmax(self.feedforward(x)),y)\n",
    "                        for (x,y) in test_data]\n",
    "        return sum(int(x==y) for (x,y) in test_results)\n",
    "\n",
    "    def cost_derivative(self,output_activations,y):\n",
    "        return output_activations -y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Network_copy(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"The list ``sizes`` contains the number of neurons in the\n",
    "        respective layers of the network.  For example, if the list\n",
    "        was [2, 3, 1] then it would be a three-layer network, with the\n",
    "        first layer containing 2 neurons, the second layer 3 neurons,\n",
    "        and the third layer 1 neuron.  The biases and weights for the\n",
    "        network are initialized randomly, using a Gaussian\n",
    "        distribution with mean 0, and variance 1.  Note that the first\n",
    "        layer is assumed to be an input layer, and by convention we\n",
    "        won't set any biases for those neurons, since biases are only\n",
    "        ever used in computing the outputs from later layers.\"\"\"\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a)+b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            test_data=None):\n",
    "        \"\"\"Train the neural network using mini-batch stochastic\n",
    "        gradient descent.  The ``training_data`` is a list of tuples\n",
    "        ``(x, y)`` representing the training inputs and the desired\n",
    "        outputs.  The other non-optional parameters are\n",
    "        self-explanatory.  If ``test_data`` is provided then the\n",
    "        network will be evaluated against the test data after each\n",
    "        epoch, and partial progress printed out.  This is useful for\n",
    "        tracking progress, but slows things down substantially.\"\"\"\n",
    "        if test_data: n_test = len(test_data)\n",
    "        n = len(training_data)\n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            if test_data:\n",
    "                print (\"Epoch {0}: {1} / {2}\".format(\n",
    "                    j, self.evaluate(test_data), n_test))\n",
    "            else:\n",
    "                print (\"Epoch {0} complete\".format(j))\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        \"\"\"Update the network's weights and biases by applying\n",
    "        gradient descent using backpropagation to a single mini batch.\n",
    "        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``\n",
    "        is the learning rate.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        self.weights = [w-(eta/len(mini_batch))*nw\n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                       for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "        gradient for the cost function C_x.  ``nabla_b`` and\n",
    "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs = [] # list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        # backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * \\\n",
    "            sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        # Note that the variable l in the loop below is used a little\n",
    "        # differently to the notation in Chapter 2 of the book.  Here,\n",
    "        # l = 1 means the last layer of neurons, l = 2 is the\n",
    "        # second-last layer, and so on.  It's a renumbering of the\n",
    "        # scheme in the book, used here to take advantage of the fact\n",
    "        # that Python can use negative indices in lists.\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"Return the number of test inputs for which the neural\n",
    "        network outputs the correct result. Note that the neural\n",
    "        network's output is assumed to be the index of whichever\n",
    "        neuron in the final layer has the highest activation.\"\"\"\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
    "                        for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"Return the vector of partial derivatives \\partial C_x /\n",
    "        \\partial a for the output activations.\"\"\"\n",
    "        return (output_activations-y)\n",
    "\n",
    "#### Miscellaneous functions\n",
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Return the MNIST data as a tuple containing the training data,\n",
    "    the validation data, and the test data.\n",
    "\n",
    "    The ``training_data`` is returned as a tuple with two entries.\n",
    "    The first entry contains the actual training images.  This is a\n",
    "    numpy ndarray with 50,000 entries.  Each entry is, in turn, a\n",
    "    numpy ndarray with 784 values, representing the 28 * 28 = 784\n",
    "    pixels in a single MNIST image.\n",
    "\n",
    "    The second entry in the ``training_data`` tuple is a numpy ndarray\n",
    "    containing 50,000 entries.  Those entries are just the digit\n",
    "    values (0...9) for the corresponding images contained in the first\n",
    "    entry of the tuple.\n",
    "\n",
    "    The ``validation_data`` and ``test_data`` are similar, except\n",
    "    each contains only 10,000 images.\n",
    "\n",
    "    This is a nice data format, but for use in neural networks it's\n",
    "    helpful to modify the format of the ``training_data`` a little.\n",
    "    That's done in the wrapper function ``load_data_wrapper()``, see\n",
    "    below.\n",
    "    \"\"\"\n",
    "    f = gzip.open('./data/mnist.pkl.gz', 'rb')\n",
    "    training_data, validation_data, test_data = pickle.load(f, encoding=\"latin1\")\n",
    "    f.close()\n",
    "    return (training_data, validation_data, test_data)\n",
    "\n",
    "def load_data_wrapper():\n",
    "    \"\"\"Return a tuple containing ``(training_data, validation_data,\n",
    "    test_data)``. Based on ``load_data``, but the format is more\n",
    "    convenient for use in our implementation of neural networks.\n",
    "\n",
    "    In particular, ``training_data`` is a list containing 50,000\n",
    "    2-tuples ``(x, y)``.  ``x`` is a 784-dimensional numpy.ndarray\n",
    "    containing the input image.  ``y`` is a 10-dimensional\n",
    "    numpy.ndarray representing the unit vector corresponding to the\n",
    "    correct digit for ``x``.\n",
    "\n",
    "    ``validation_data`` and ``test_data`` are lists containing 10,000\n",
    "    2-tuples ``(x, y)``.  In each case, ``x`` is a 784-dimensional\n",
    "    numpy.ndarry containing the input image, and ``y`` is the\n",
    "    corresponding classification, i.e., the digit values (integers)\n",
    "    corresponding to ``x``.\n",
    "\n",
    "    Obviously, this means we're using slightly different formats for\n",
    "    the training data and the validation / test data.  These formats\n",
    "    turn out to be the most convenient for use in our neural network\n",
    "    code.\"\"\"\n",
    "    tr_d, va_d, te_d = load_data()\n",
    "    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]\n",
    "    training_results = [vectorized_result(y) for y in tr_d[1]]\n",
    "    training_data = list(zip(training_inputs, training_results))\n",
    "    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]\n",
    "    validation_data = list(zip(validation_inputs, va_d[1]))\n",
    "    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]\n",
    "    test_data = list(zip(test_inputs, te_d[1]))\n",
    "    return (training_data, validation_data, test_data)\n",
    "\n",
    "def vectorized_result(j):\n",
    "    \"\"\"Return a 10-dimensional unit vector with a 1.0 in the jth\n",
    "    position and zeroes elsewhere.  This is used to convert a digit\n",
    "    (0...9) into a corresponding desired output from the neural\n",
    "    network.\"\"\"\n",
    "    e = np.zeros((10, 1))\n",
    "    e[j] = 1.0\n",
    "    return e"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data  = load_data_wrapper()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "net = Network([784, 30, 10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mnet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSGD\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_data\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn [5], line 21\u001B[0m, in \u001B[0;36mNetwork.SGD\u001B[1;34m(self, training_data, epochs, mini_batch_size, eta, test_data)\u001B[0m\n\u001B[0;32m     18\u001B[0m mini_batches \u001B[38;5;241m=\u001B[39m [training_data[k:k\u001B[38;5;241m+\u001B[39mmini_batch_size]\n\u001B[0;32m     19\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m,n,mini_batch_size)]\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mini_batch \u001B[38;5;129;01min\u001B[39;00m mini_batches:\n\u001B[1;32m---> 21\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate_mini_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmini_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43meta\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m test_data:\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mj\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluate(test_data)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m / \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_test\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn [5], line 34\u001B[0m, in \u001B[0;36mNetwork.update_mini_batch\u001B[1;34m(self, mini_batch, eta)\u001B[0m\n\u001B[0;32m     32\u001B[0m     delta_new_b,delta_new_w \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackprop(x,y)\n\u001B[0;32m     33\u001B[0m     new_b \u001B[38;5;241m=\u001B[39m [nb\u001B[38;5;241m+\u001B[39mdnb \u001B[38;5;28;01mfor\u001B[39;00m nb,dnb \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(new_b,delta_new_b)]\n\u001B[1;32m---> 34\u001B[0m     new_w \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[43mnw\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mdnw\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnw\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdnw\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnew_w\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdelta_new_w\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights \u001B[38;5;241m=\u001B[39m [w \u001B[38;5;241m-\u001B[39m(eta\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(mini_batch))\u001B[38;5;241m*\u001B[39mnw\n\u001B[0;32m     37\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m w,nw \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights,new_w)]\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;241m=\u001B[39m [b\u001B[38;5;241m-\u001B[39m (eta\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(mini_batch))\u001B[38;5;241m*\u001B[39mnb\n\u001B[0;32m     39\u001B[0m              \u001B[38;5;28;01mfor\u001B[39;00m b, nb \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias,new_b)]\n",
      "Cell \u001B[1;32mIn [5], line 34\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     32\u001B[0m     delta_new_b,delta_new_w \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackprop(x,y)\n\u001B[0;32m     33\u001B[0m     new_b \u001B[38;5;241m=\u001B[39m [nb\u001B[38;5;241m+\u001B[39mdnb \u001B[38;5;28;01mfor\u001B[39;00m nb,dnb \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(new_b,delta_new_b)]\n\u001B[1;32m---> 34\u001B[0m     new_w \u001B[38;5;241m=\u001B[39m [nw\u001B[38;5;241m+\u001B[39mdnw \u001B[38;5;28;01mfor\u001B[39;00m nw,dnw \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(new_w,delta_new_w)]\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights \u001B[38;5;241m=\u001B[39m [w \u001B[38;5;241m-\u001B[39m(eta\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(mini_batch))\u001B[38;5;241m*\u001B[39mnw\n\u001B[0;32m     37\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m w,nw \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights,new_w)]\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;241m=\u001B[39m [b\u001B[38;5;241m-\u001B[39m (eta\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(mini_batch))\u001B[38;5;241m*\u001B[39mnb\n\u001B[0;32m     39\u001B[0m              \u001B[38;5;28;01mfor\u001B[39;00m b, nb \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias,new_b)]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "net.SGD(training_data, 10, 10, 3.0, test_data=test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(y, a)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy as sp\n",
    "y_sp,a_sp = sp.symbols(\"y a\")\n",
    "y_sp,a_sp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(a - y)/(a*(1 - a))",
      "text/latex": "$\\displaystyle \\frac{a - y}{a \\left(1 - a\\right)}$"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr = (a_sp - y_sp) /( a_sp*(1-a_sp))\n",
    "expr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "-y*log(a) + (y - 1)*log(a - 1)",
      "text/latex": "$\\displaystyle - y \\log{\\left(a \\right)} + \\left(y - 1\\right) \\log{\\left(a - 1 \\right)}$"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.simplify(sp.integrate(expr,a_sp))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}